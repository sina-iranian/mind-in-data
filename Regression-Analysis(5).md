## ğŸ“‰ 4ï¸âƒ£ Regression Analysis

### ğŸ”¹ Purpose
Regression quantifies how **independent variables (X)** affect a **dependent variable (Y)**.  
Itâ€™s used for **prediction**, **trend analysis**, and **explanatory modeling**.

---

### ğŸ”¹ Linear Regression Model
\[
\hat{y} = b_0 + b_1 x_1 + \varepsilon
\]

- **bâ‚€:** intercept (baseline value)  
- **bâ‚:** slope (change in Y for one-unit change in X)  
- **Îµ:** random error term  

---

### ğŸ”¹ Correlation vs Regression

| Aspect | Correlation | Regression |
|---------|--------------|-------------|
| **Measures** | Association | Cause-effect |
| **Symmetry** | Symmetric | Directional |
| **Output** | Single r-value | Predictive equation |

---

### ğŸ”¹ Core Metrics

| Metric | Meaning | Range / Interpretation |
|---------|----------|------------------------|
| **RÂ²** | % variance in Y explained by X | 0 â†’ 1 |
| **Adjusted RÂ²** | RÂ² adjusted for number of predictors | Penalizes unnecessary variables |
| **t-stat / p-value** | Tests variable significance | p < 0.05 â†’ significant |
| **F-statistic** | Tests overall model fit | p < 0.05 â†’ model valid |

---

### ğŸ”¹ OLS Assumptions

| Assumption | Meaning |
|-------------|----------|
| **Linearity** | Relationship between X and Y is linear |
| **No Endogeneity** | Errors not correlated with predictors |
| **Homoscedasticity** | Constant error variance |
| **No Autocorrelation** | Errors independent across observations |
| **No Multicollinearity** | Predictors not highly correlated |

---

### ğŸ”¹ Common Methods
- **OLS (Ordinary Least Squares):** simplest, baseline estimator  
- **GLS (Generalized Least Squares):** fixes heteroscedasticity  
- **MLE (Maximum Likelihood Estimation):** optimizes parameters  
- **Bayesian Regression:** adds prior beliefs  
- **Kernel / Gaussian Processes:** nonlinear alternatives  

---

### ğŸ”¹ Interpretation
- **Intercept (bâ‚€):** expected Y when all X = 0  
- **Slope (báµ¢):** average change in Y per 1-unit change in X  
- **p < 0.05:** coefficient statistically significant  
- **High RÂ²:** strong explanatory power, but check for overfitting  
